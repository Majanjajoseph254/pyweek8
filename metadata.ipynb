{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d14759",
   "metadata": {},
   "source": [
    "# CORD-19 Dataset Analysis\n",
    "\n",
    "This notebook contains a comprehensive analysis of the CORD-19 research dataset metadata. We'll explore the dataset structure, clean the data, and create meaningful visualizations to understand COVID-19 research patterns.\n",
    "\n",
    "## Dataset Overview\n",
    "The CORD-19 dataset contains metadata for COVID-19 research papers including:\n",
    "- Paper titles and abstracts\n",
    "- Publication dates\n",
    "- Authors and journals\n",
    "- Source information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f229c61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Pandas version: 2.3.2\n",
      "NumPy version: 2.3.2\n",
      "Matplotlib version: 3.10.6\n",
      "Seaborn version: 0.13.2\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except OSError:\n",
    "    try:\n",
    "        plt.style.use('seaborn')\n",
    "    except OSError:\n",
    "        plt.style.use('default')\n",
    "        print(\"Using default matplotlib style\")\n",
    "\n",
    "# Set seaborn style and palette\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set default figure size\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a321c899",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65ed3015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1000, 12)\n",
      "\n",
      "Column Names:\n",
      "['cord_uid', 'title', 'abstract', 'authors', 'journal', 'publish_time', 'source_x', 'has_full_text', 'pdf_json_files', 'pmc_json_files', 'url', 'doi']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>source_x</th>\n",
       "      <th>has_full_text</th>\n",
       "      <th>pdf_json_files</th>\n",
       "      <th>pmc_json_files</th>\n",
       "      <th>url</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cord_000000</td>\n",
       "      <td>COVID-19 Research Paper 0: Preventive Clinical</td>\n",
       "      <td>This study investigates COVID-19 symptoms usin...</td>\n",
       "      <td>Author 0 Williams, Author 1 Garcia</td>\n",
       "      <td>PLOS ONE</td>\n",
       "      <td>2021-12-11</td>\n",
       "      <td>Research Square</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://example.com/paper/0</td>\n",
       "      <td>10.1000/000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cord_000001</td>\n",
       "      <td>COVID-19 Research Paper 1: Virological Epidemi...</td>\n",
       "      <td>This study investigates COVID-19 prevention us...</td>\n",
       "      <td>Author 0 Davis, Author 1 Jones, Author 2 Williams</td>\n",
       "      <td>PNAS</td>\n",
       "      <td>2022-09-18</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>True</td>\n",
       "      <td>pdf_1.json</td>\n",
       "      <td>pmc_1.json</td>\n",
       "      <td>https://example.com/paper/1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cord_000002</td>\n",
       "      <td>COVID-19 Research Paper 2: Preventive Preventive</td>\n",
       "      <td>This study investigates COVID-19 transmission ...</td>\n",
       "      <td>Author 0 Williams</td>\n",
       "      <td>JAMA</td>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>False</td>\n",
       "      <td>pdf_2.json</td>\n",
       "      <td>pmc_2.json</td>\n",
       "      <td>https://example.com/paper/2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cord_000003</td>\n",
       "      <td>COVID-19 Research Paper 3: Mathematical Modeli...</td>\n",
       "      <td>This study investigates COVID-19 epidemiology ...</td>\n",
       "      <td>Author 0 Jones, Author 1 Jones, Author 2 Garci...</td>\n",
       "      <td>BMJ</td>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>Research Square</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pmc_3.json</td>\n",
       "      <td>https://example.com/paper/3</td>\n",
       "      <td>10.1000/000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cord_000004</td>\n",
       "      <td>COVID-19 Research Paper 4: Therapeutic Clinical</td>\n",
       "      <td>This study investigates COVID-19 transmission ...</td>\n",
       "      <td>Author 0 Miller</td>\n",
       "      <td>Nature</td>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>Research Square</td>\n",
       "      <td>True</td>\n",
       "      <td>pdf_4.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://example.com/paper/4</td>\n",
       "      <td>10.1000/000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cord_uid                                              title  \\\n",
       "0  cord_000000     COVID-19 Research Paper 0: Preventive Clinical   \n",
       "1  cord_000001  COVID-19 Research Paper 1: Virological Epidemi...   \n",
       "2  cord_000002   COVID-19 Research Paper 2: Preventive Preventive   \n",
       "3  cord_000003  COVID-19 Research Paper 3: Mathematical Modeli...   \n",
       "4  cord_000004    COVID-19 Research Paper 4: Therapeutic Clinical   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  This study investigates COVID-19 symptoms usin...   \n",
       "1  This study investigates COVID-19 prevention us...   \n",
       "2  This study investigates COVID-19 transmission ...   \n",
       "3  This study investigates COVID-19 epidemiology ...   \n",
       "4  This study investigates COVID-19 transmission ...   \n",
       "\n",
       "                                             authors   journal publish_time  \\\n",
       "0                 Author 0 Williams, Author 1 Garcia  PLOS ONE   2021-12-11   \n",
       "1  Author 0 Davis, Author 1 Jones, Author 2 Williams      PNAS   2022-09-18   \n",
       "2                                  Author 0 Williams      JAMA   2020-01-11   \n",
       "3  Author 0 Jones, Author 1 Jones, Author 2 Garci...       BMJ   2020-11-20   \n",
       "4                                    Author 0 Miller    Nature   2022-12-04   \n",
       "\n",
       "          source_x  has_full_text pdf_json_files pmc_json_files  \\\n",
       "0  Research Square          False            NaN            NaN   \n",
       "1         Elsevier           True     pdf_1.json     pmc_1.json   \n",
       "2         Elsevier          False     pdf_2.json     pmc_2.json   \n",
       "3  Research Square          False            NaN     pmc_3.json   \n",
       "4  Research Square           True     pdf_4.json            NaN   \n",
       "\n",
       "                           url             doi  \n",
       "0  https://example.com/paper/0  10.1000/000000  \n",
       "1  https://example.com/paper/1             NaN  \n",
       "2  https://example.com/paper/2             NaN  \n",
       "3  https://example.com/paper/3  10.1000/000003  \n",
       "4  https://example.com/paper/4  10.1000/000004  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('cord19_metadata.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edf4ae9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   cord_uid        1000 non-null   object\n",
      " 1   title           1000 non-null   object\n",
      " 2   abstract        980 non-null    object\n",
      " 3   authors         1000 non-null   object\n",
      " 4   journal         985 non-null    object\n",
      " 5   publish_time    1000 non-null   object\n",
      " 6   source_x        1000 non-null   object\n",
      " 7   has_full_text   1000 non-null   bool  \n",
      " 8   pdf_json_files  494 non-null    object\n",
      " 9   pmc_json_files  498 non-null    object\n",
      " 10  url             1000 non-null   object\n",
      " 11  doi             672 non-null    object\n",
      "dtypes: bool(1), object(11)\n",
      "memory usage: 87.0+ KB\n",
      "\n",
      "Data Types:\n",
      "cord_uid          object\n",
      "title             object\n",
      "abstract          object\n",
      "authors           object\n",
      "journal           object\n",
      "publish_time      object\n",
      "source_x          object\n",
      "has_full_text       bool\n",
      "pdf_json_files    object\n",
      "pmc_json_files    object\n",
      "url               object\n",
      "doi               object\n",
      "dtype: object\n",
      "\n",
      "Missing Values:\n",
      "cord_uid            0\n",
      "title               0\n",
      "abstract           20\n",
      "authors             0\n",
      "journal            15\n",
      "publish_time        0\n",
      "source_x            0\n",
      "has_full_text       0\n",
      "pdf_json_files    506\n",
      "pmc_json_files    502\n",
      "url                 0\n",
      "doi               328\n",
      "dtype: int64\n",
      "\n",
      "Missing Values Percentage:\n",
      "cord_uid           0.0\n",
      "title              0.0\n",
      "abstract           2.0\n",
      "authors            0.0\n",
      "journal            1.5\n",
      "publish_time       0.0\n",
      "source_x           0.0\n",
      "has_full_text      0.0\n",
      "pdf_json_files    50.6\n",
      "pmc_json_files    50.2\n",
      "url                0.0\n",
      "doi               32.8\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Dataset information and data types\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nMissing Values Percentage:\")\n",
    "print((df.isnull().sum() / len(df)) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9483d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for numerical columns\n",
    "print(\"Basic Statistics:\")\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4c6f27",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecdcc890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning completed!\n",
      "Date range: 2020-01-01 00:00:00 to 2022-12-31 00:00:00\n",
      "Years covered: [np.int32(2020), np.int32(2021), np.int32(2022)]\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Convert publish_time to datetime\n",
    "df_clean['publish_time'] = pd.to_datetime(df_clean['publish_time'], errors='coerce')\n",
    "\n",
    "# Extract year and month for analysis\n",
    "df_clean['publish_year'] = df_clean['publish_time'].dt.year\n",
    "df_clean['publish_month'] = df_clean['publish_time'].dt.month\n",
    "\n",
    "# Handle missing values in abstracts by replacing with empty string\n",
    "df_clean['abstract'] = df_clean['abstract'].fillna('No abstract available')\n",
    "\n",
    "# Handle missing journal values\n",
    "df_clean['journal'] = df_clean['journal'].fillna('Unknown Journal')\n",
    "\n",
    "# Handle missing DOI values\n",
    "df_clean['doi'] = df_clean['doi'].fillna('No DOI available')\n",
    "\n",
    "print(\"Data cleaning completed!\")\n",
    "print(f\"Date range: {df_clean['publish_time'].min()} to {df_clean['publish_time'].max()}\")\n",
    "print(f\"Years covered: {sorted(df_clean['publish_year'].dropna().unique())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cdfd01",
   "metadata": {},
   "source": [
    "## 3. Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce57a7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publications by Year:\n",
      "publish_year\n",
      "2020    341\n",
      "2021    343\n",
      "2022    316\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 Journals:\n",
      "journal\n",
      "The Lancet                      96\n",
      "Science                         95\n",
      "PLOS ONE                        92\n",
      "Clinical Infectious Diseases    79\n",
      "Journal of Medical Virology     77\n",
      "Nature                          74\n",
      "Emerging Infectious Diseases    73\n",
      "BMJ                             72\n",
      "Nature Medicine                 70\n",
      "PNAS                            68\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Source Distribution:\n",
      "source_x\n",
      "Elsevier           177\n",
      "bioRxiv            171\n",
      "Research Square    168\n",
      "medRxiv            166\n",
      "WHO                165\n",
      "PubMed Central     153\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Full Text Availability:\n",
      "has_full_text\n",
      "False    529\n",
      "True     471\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Publication trends by year\n",
    "publication_by_year = df_clean['publish_year'].value_counts().sort_index()\n",
    "print(\"Publications by Year:\")\n",
    "print(publication_by_year)\n",
    "\n",
    "# Top journals\n",
    "top_journals = df_clean['journal'].value_counts().head(10)\n",
    "print(\"\\nTop 10 Journals:\")\n",
    "print(top_journals)\n",
    "\n",
    "# Source distribution\n",
    "source_distribution = df_clean['source_x'].value_counts()\n",
    "print(\"\\nSource Distribution:\")\n",
    "print(source_distribution)\n",
    "\n",
    "# Full text availability\n",
    "full_text_availability = df_clean['has_full_text'].value_counts()\n",
    "print(\"\\nFull Text Availability:\")\n",
    "print(full_text_availability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be863ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author Statistics:\n",
      "Average authors per paper: 3.56\n",
      "Median authors per paper: 4.00\n",
      "Max authors per paper: 6\n",
      "Min authors per paper: 1\n",
      "\n",
      "Abstract Statistics:\n",
      "Average abstract length: 135 characters\n",
      "Median abstract length: 138 characters\n"
     ]
    }
   ],
   "source": [
    "# Author analysis\n",
    "# Count number of authors per paper\n",
    "df_clean['author_count'] = df_clean['authors'].str.split(',').str.len()\n",
    "\n",
    "print(\"Author Statistics:\")\n",
    "print(f\"Average authors per paper: {df_clean['author_count'].mean():.2f}\")\n",
    "print(f\"Median authors per paper: {df_clean['author_count'].median():.2f}\")\n",
    "print(f\"Max authors per paper: {df_clean['author_count'].max()}\")\n",
    "print(f\"Min authors per paper: {df_clean['author_count'].min()}\")\n",
    "\n",
    "# Abstract length analysis\n",
    "df_clean['abstract_length'] = df_clean['abstract'].str.len()\n",
    "print(f\"\\nAbstract Statistics:\")\n",
    "print(f\"Average abstract length: {df_clean['abstract_length'].mean():.0f} characters\")\n",
    "print(f\"Median abstract length: {df_clean['abstract_length'].median():.0f} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfed7bec",
   "metadata": {},
   "source": [
    "## 4. Data Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plotting style\n",
    "plt.rcParams['figure.figsize'] = (16, 12)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Publications by Year\n",
    "if not publication_by_year.empty:\n",
    "    axes[0, 0].bar(publication_by_year.index, publication_by_year.values, \n",
    "                   color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "    axes[0, 0].set_title('Publications by Year', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Year')\n",
    "    axes[0, 0].set_ylabel('Number of Publications')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    # Format x-axis to show integers\n",
    "    axes[0, 0].set_xticks(publication_by_year.index)\n",
    "    axes[0, 0].set_xticklabels(publication_by_year.index.astype(int))\n",
    "\n",
    "# 2. Top 10 Journals\n",
    "if not top_journals.empty:\n",
    "    top_journals_plot = top_journals.head(10)\n",
    "    y_pos = range(len(top_journals_plot))\n",
    "    axes[0, 1].barh(y_pos, top_journals_plot.values, \n",
    "                    color='lightcoral', edgecolor='darkred', alpha=0.7)\n",
    "    axes[0, 1].set_yticks(y_pos)\n",
    "    axes[0, 1].set_yticklabels(top_journals_plot.index)\n",
    "    axes[0, 1].set_title('Top 10 Journals', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Number of Publications')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Source Distribution\n",
    "if not source_distribution.empty:\n",
    "    # Handle case where there might be too many sources\n",
    "    if len(source_distribution) > 10:\n",
    "        # Show top 10 sources and group others as \"Others\"\n",
    "        top_sources = source_distribution.head(9)\n",
    "        others_count = source_distribution.tail(len(source_distribution) - 9).sum()\n",
    "        plot_sources = pd.concat([top_sources, pd.Series([others_count], index=['Others'])])\n",
    "        plot_labels = plot_sources.index\n",
    "        plot_values = plot_sources.values\n",
    "    else:\n",
    "        plot_labels = source_distribution.index\n",
    "        plot_values = source_distribution.values\n",
    "    \n",
    "    axes[1, 0].pie(plot_values, labels=plot_labels, autopct='%1.1f%%', startangle=90)\n",
    "    axes[1, 0].set_title('Source Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 4. Author Count Distribution\n",
    "if 'author_count' in df_clean.columns and not df_clean['author_count'].empty:\n",
    "    # Ensure we have valid data for histogram\n",
    "    valid_author_counts = df_clean['author_count'].dropna()\n",
    "    if not valid_author_counts.empty:\n",
    "        max_bins = min(20, len(valid_author_counts.unique()))\n",
    "        axes[1, 1].hist(valid_author_counts, bins=max_bins, \n",
    "                       color='lightgreen', edgecolor='darkgreen', alpha=0.7)\n",
    "        axes[1, 1].set_title('Distribution of Author Count per Paper', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Number of Authors')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "208a054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Monthly publication trends\n",
    "try:\n",
    "    monthly_publications = df_clean.groupby(['publish_year', 'publish_month']).size().reset_index(name='count')\n",
    "    if not monthly_publications.empty:\n",
    "        monthly_publications['date'] = pd.to_datetime(monthly_publications[['publish_year', 'publish_month']].assign(day=1))\n",
    "        \n",
    "        axes[0, 0].plot(monthly_publications['date'], monthly_publications['count'], \n",
    "                       marker='o', linewidth=2, markersize=4, color='steelblue')\n",
    "        axes[0, 0].set_title('Monthly Publication Trends', fontsize=14, fontweight='bold')\n",
    "        axes[0, 0].set_xlabel('Date')\n",
    "        axes[0, 0].set_ylabel('Number of Publications')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    else:\n",
    "        axes[0, 0].text(0.5, 0.5, 'No monthly data available', ha='center', va='center', transform=axes[0, 0].transAxes)\n",
    "        axes[0, 0].set_title('Monthly Publication Trends', fontsize=14, fontweight='bold')\n",
    "except Exception as e:\n",
    "    axes[0, 0].text(0.5, 0.5, f'Error: {str(e)}', ha='center', va='center', transform=axes[0, 0].transAxes)\n",
    "    axes[0, 0].set_title('Monthly Publication Trends', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Full text availability\n",
    "if not full_text_availability.empty:\n",
    "    full_text_labels = ['Available', 'Not Available']\n",
    "    full_text_counts = [full_text_availability.get(True, 0), full_text_availability.get(False, 0)]\n",
    "    colors = ['lightgreen', 'lightcoral']\n",
    "    \n",
    "    # Only plot if we have data\n",
    "    if sum(full_text_counts) > 0:\n",
    "        axes[0, 1].pie(full_text_counts, labels=full_text_labels, autopct='%1.1f%%', \n",
    "                      colors=colors, startangle=90)\n",
    "    axes[0, 1].set_title('Full Text Availability', fontsize=14, fontweight='bold')\n",
    "else:\n",
    "    axes[0, 1].text(0.5, 0.5, 'No full text data available', ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "    axes[0, 1].set_title('Full Text Availability', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3. Abstract length distribution\n",
    "if 'abstract_length' in df_clean.columns:\n",
    "    valid_abstracts = df_clean['abstract_length'].dropna()\n",
    "    if not valid_abstracts.empty:\n",
    "        # Use a reasonable number of bins based on data range\n",
    "        max_bins = min(30, len(valid_abstracts.unique()))\n",
    "        axes[1, 0].hist(valid_abstracts, bins=max_bins, \n",
    "                       color='lightblue', edgecolor='navy', alpha=0.7)\n",
    "        axes[1, 0].set_title('Abstract Length Distribution', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Abstract Length (characters)')\n",
    "        axes[1, 0].set_ylabel('Frequency')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, 'No abstract length data', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "        axes[1, 0].set_title('Abstract Length Distribution', fontsize=14, fontweight='bold')\n",
    "else:\n",
    "    axes[1, 0].text(0.5, 0.5, 'Abstract length not calculated', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "    axes[1, 0].set_title('Abstract Length Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 4. Publications by source\n",
    "if not source_distribution.empty:\n",
    "    # Limit to top sources to avoid overcrowding\n",
    "    top_sources = source_distribution.head(10)\n",
    "    x_pos = range(len(top_sources))\n",
    "    \n",
    "    axes[1, 1].bar(x_pos, top_sources.values, color='orange', edgecolor='darkorange', alpha=0.7)\n",
    "    axes[1, 1].set_xticks(x_pos)\n",
    "    axes[1, 1].set_xticklabels(top_sources.index, rotation=45, ha='right')\n",
    "    axes[1, 1].set_title('Publications by Source (Top 10)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Number of Publications')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'No source data available', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "    axes[1, 1].set_title('Publications by Source', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d572b03a",
   "metadata": {},
   "source": [
    "## 5. Key Insights and Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f5f3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CORD-19 Dataset Analysis Summary ===\n",
      "\n",
      "📊 Dataset Overview:\n",
      "   • Total papers: 1,000\n",
      "   • Date range: 2020-01-01 to 2022-12-31\n",
      "   • Years covered: [np.int32(2020), np.int32(2021), np.int32(2022)]\n",
      "\n",
      "📚 Publication Patterns:\n",
      "   • Most active year: 2021 (343 papers)\n",
      "   • Average authors per paper: 3.6\n",
      "   • Average abstract length: 135 characters\n",
      "\n",
      "🏆 Top Publishing Sources:\n",
      "   1. Elsevier: 177 papers (17.7%)\n",
      "   2. bioRxiv: 171 papers (17.1%)\n",
      "   3. Research Square: 168 papers (16.8%)\n",
      "\n",
      "📖 Journal Distribution:\n",
      "   • Total unique journals: 14\n",
      "   • Top journal: The Lancet (96 papers)\n",
      "\n",
      "📄 Full Text Availability:\n",
      "   • Papers with full text: 471 (47.1%)\n",
      "   • Papers without full text: 529 (52.9%)\n",
      "\n",
      "🔍 Data Quality:\n",
      "   • Missing abstracts: 2.0%\n",
      "   • Missing journal info: 1.5%\n",
      "\n",
      "✅ Analysis completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Generate summary statistics and insights\n",
    "print(\"=== CORD-19 Dataset Analysis Summary ===\\n\")\n",
    "\n",
    "print(f\"📊 Dataset Overview:\")\n",
    "print(f\"   • Total papers: {len(df_clean):,}\")\n",
    "\n",
    "# Handle date range safely\n",
    "try:\n",
    "    min_date = df_clean['publish_time'].min()\n",
    "    max_date = df_clean['publish_time'].max()\n",
    "    if pd.notna(min_date) and pd.notna(max_date):\n",
    "        print(f\"   • Date range: {min_date.strftime('%Y-%m-%d')} to {max_date.strftime('%Y-%m-%d')}\")\n",
    "    else:\n",
    "        print(\"   • Date range: Unable to determine\")\n",
    "except:\n",
    "    print(\"   • Date range: Unable to determine\")\n",
    "\n",
    "# Handle years safely\n",
    "try:\n",
    "    years = sorted(df_clean['publish_year'].dropna().unique())\n",
    "    print(f\"   • Years covered: {years}\")\n",
    "except:\n",
    "    print(\"   • Years covered: Unable to determine\")\n",
    "\n",
    "print(f\"\\n📚 Publication Patterns:\")\n",
    "try:\n",
    "    if not publication_by_year.empty:\n",
    "        print(f\"   • Most active year: {publication_by_year.idxmax()} ({publication_by_year.max()} papers)\")\n",
    "    else:\n",
    "        print(\"   • Most active year: Unable to determine\")\n",
    "except:\n",
    "    print(\"   • Most active year: Unable to determine\")\n",
    "\n",
    "try:\n",
    "    if 'author_count' in df_clean.columns:\n",
    "        avg_authors = df_clean['author_count'].mean()\n",
    "        print(f\"   • Average authors per paper: {avg_authors:.1f}\")\n",
    "    else:\n",
    "        print(\"   • Average authors per paper: Not calculated\")\n",
    "except:\n",
    "    print(\"   • Average authors per paper: Unable to calculate\")\n",
    "\n",
    "try:\n",
    "    if 'abstract_length' in df_clean.columns:\n",
    "        avg_abstract = df_clean['abstract_length'].mean()\n",
    "        print(f\"   • Average abstract length: {avg_abstract:.0f} characters\")\n",
    "    else:\n",
    "        print(\"   • Average abstract length: Not calculated\")\n",
    "except:\n",
    "    print(\"   • Average abstract length: Unable to calculate\")\n",
    "\n",
    "print(f\"\\n🏆 Top Publishing Sources:\")\n",
    "try:\n",
    "    if not source_distribution.empty:\n",
    "        for i, (source, count) in enumerate(source_distribution.head(3).items(), 1):\n",
    "            percentage = (count / len(df_clean)) * 100\n",
    "            print(f\"   {i}. {source}: {count} papers ({percentage:.1f}%)\")\n",
    "    else:\n",
    "        print(\"   No source data available\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error processing sources: {str(e)}\")\n",
    "\n",
    "print(f\"\\n📖 Journal Distribution:\")\n",
    "try:\n",
    "    journal_count = df_clean['journal'].nunique()\n",
    "    print(f\"   • Total unique journals: {journal_count}\")\n",
    "    \n",
    "    if not top_journals.empty:\n",
    "        print(f\"   • Top journal: {top_journals.index[0]} ({top_journals.iloc[0]} papers)\")\n",
    "    else:\n",
    "        print(\"   • Top journal: Unable to determine\")\n",
    "except:\n",
    "    print(\"   • Journal information: Unable to process\")\n",
    "\n",
    "print(f\"\\n📄 Full Text Availability:\")\n",
    "try:\n",
    "    if not full_text_availability.empty:\n",
    "        true_count = full_text_availability.get(True, 0)\n",
    "        false_count = full_text_availability.get(False, 0)\n",
    "        total_count = true_count + false_count\n",
    "        \n",
    "        if total_count > 0:\n",
    "            full_text_pct = (true_count / total_count) * 100\n",
    "            print(f\"   • Papers with full text: {true_count} ({full_text_pct:.1f}%)\")\n",
    "            print(f\"   • Papers without full text: {false_count} ({100-full_text_pct:.1f}%)\")\n",
    "        else:\n",
    "            print(\"   • No full text data available\")\n",
    "    else:\n",
    "        print(\"   • No full text data available\")\n",
    "except Exception as e:\n",
    "    print(f\"   • Error processing full text data: {str(e)}\")\n",
    "\n",
    "print(f\"\\n🔍 Data Quality:\")\n",
    "try:\n",
    "    missing_abstract_pct = (df_clean['abstract'] == 'No abstract available').sum() / len(df_clean) * 100\n",
    "    missing_journal_pct = (df_clean['journal'] == 'Unknown Journal').sum() / len(df_clean) * 100\n",
    "    print(f\"   • Missing abstracts: {missing_abstract_pct:.1f}%\")\n",
    "    print(f\"   • Missing journal info: {missing_journal_pct:.1f}%\")\n",
    "except:\n",
    "    print(\"   • Data quality metrics: Unable to calculate\")\n",
    "\n",
    "print(\"\\n✅ Analysis completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
